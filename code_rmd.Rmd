---
title: "The Spotify Project"
author: "Arnob Chanda, Kai Mei, Hanying Chen"
date: "11/10/2021"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

Intro here

## EDA and cleaning

### General Cleaning

```{r}
df <- read.csv("top10s.csv")
summary(df)
```

First column 'X' is redundant so removing it. Also take a look at the summary statistics.

```{r}
df <- subset(df, select = -X)
summary(df)
```

Checking if any title is repeated.

```{r}
unique_titles <- unique(df[c("title")])
nrow(unique_titles)
```

We have 584 unique values, out of 603 total values. So we have 19 repeated titles.

```{r}
n_title_repeat <- data.frame(table(df$title))
n_title_repeat[n_title_repeat$Freq > 1, ]
```

Checking if everything is the same in the repeated titles by creating a data frame with only the repeated values, sorting it and checking what is different.

```{r}
repeated_titles <- df[df$title %in% n_title_repeat$Var1[n_title_repeat$Freq > 1], ]
library(dplyr)
repeated_titles_sorted <- arrange(repeated_titles, title)
head(repeated_titles_sorted)
```

Looking at the data, we can see that there are some songs, the only difference is the year.
For others, the artist name is different. 
If the only difference is the year, we remove the second occurrence of it, else we keep the row.

```{r}
#Start with Repeated column set to FALSE
df$Repeated = FALSE
#Iterate over all the rows in the data frame
for(i in 1:nrow(df))
{
  #Get the indexes of the repeated values
  same_title_index = which(df$title == df$title[i])
  if(length(same_title_index)>1)
  {
    #The first occurrence is same_title_index[1], second one is same_title_index[2]
    #Check artist name for both indexes and if its the same artist name mark the second occurrence as TRUE
    if(df[same_title_index[1],]$artist == df[same_title_index[2],]$artist)
    {
      df[same_title_index[2],]$Repeated = TRUE
    }
  }
}

summary(df)
```

So, out of the 19 titles having the same names, 16 of them have the same artist name.
The second occurrence of the same title and artist has been marked TRUE.
Based on this, we can remove those repeated rows and make a cleaner data frame.

```{r}
rows_to_be_deleted <- which(df$Repeated == TRUE)
df_clean <- df[-c(rows_to_be_deleted),]
df_clean <- subset(df_clean, select = -Repeated)
summary(df_clean)
```

### Check for missing data

From the summary we can see that there are no missing data.
Plotting the missing data to confirm.

```{r}
# install.packages('VIM')
library(VIM, quietly = TRUE)
aggr(df_clean)
```

As there is no missing data, we don't need to replace any rows or columns.

### Check for outliers

Using Mahal score to eliminate outliers.

```{r}
df_variables <- df_clean[,-c(1,2,3,4)]
mahal <- mahalanobis(df_variables,
                     colMeans(df_variables),
                     cov(df_variables), use = "pairwise.complete.obs")
summary(mahal)
```

```{r}
cutoff <- qchisq(1-.001, ncol(df_variables))
cutoff
```
The cutoff value of Mahal distance is 29.5883
```{r}
summary(mahal < cutoff)
```

So we have 20 outliers.
Removing it.

```{r}
noout <- subset(df_clean, mahal<cutoff)
summary(noout)
```

### Check Correlation
```{r cor}
library(corrplot, quietly = TRUE)
corrplot(cor(noout[-c(1,2,3,4)]))
```

### Visualize the distribution of `top.genre` and `year`
```{r}
library(ggplot2)
cleanup <- theme(panel.grid.major = element_blank(),
                panel.grid.minor = element_blank(),
                panel.background = element_blank(),
                axis.line.x = element_line(color = 'black'),
                axis.line.y = element_line(color = 'black'),
                legend.key = element_rect(fill = 'white'),
                text = element_text(size = 12))

genre_freq <- as.data.frame(table(df$top.genre))
year_freq <- as.data.frame(table(df$year))

bar_lot_year <- ggplot(data = year_freq, aes(x = Var1, y = Freq, fill = Var1))
bar_lot_year + 
   stat_summary(fun = mean,
                 geom = 'bar',
                 position = 'dodge',
                 ) +
    xlab("Year") +
    ylab("Count") + 
    labs(title="Number of songs by year") +
    cleanup

# We have too many genres in the dataset, so we only view the top 5 genres and group the rest into 'Others'
k <- 5
top_k_genres <- genre_freq[order(-genre_freq$Freq), ][1:k, ]
others <- subset(genre_freq, !(Var1 %in% top_k_genres$Var1))
df_others <-data.frame("others", sum(others$Freq))
names(df_others)<-c("Var1", "Freq")
# combine two dfs
df_new <- rbind(top_k_genres, df_others)

pie_genre <- ggplot(data = df_new, aes(x = "", y = Freq, fill = Var1))
pie_genre + 
    geom_col() +
    coord_polar(theta = "y") +
    scale_fill_brewer(palette = "RdYlBu") +
    guides(fill = guide_legend(title = "Genre")) +
    ggtitle("Most popular genres")+
    theme_void()
```

From year 2010 to 2019, year 2015 has the largest number of songs. The top 5 popular genres are dance pop, pop, canadian pop, barbadian pop and boy band.

### Check Assumptions
1. Additivity
```{r additivity}
# TODO: Add interpretation
model <- lm(pop ~., data = noout[-c(1,2,3,4)])  # do not include title, artist, genre or year
summary(model, correlation = TRUE)
```

2. Linearity
```{r linearity}
# TODO: Add interpretation
standardized <- rstudent(model)
fitted <- scale(model$fitted.values)
{qqnorm(standardized)
abline(0,1)}
```

3. Normality
```{r normality}
# TODO: Add interpretation
hist(standardized, breaks=15)
```

4. Homogeneity and Homoscedasticity
```{r homogs}
# TODO: Add interpretation
{plot(fitvalues, standardized) 
abline(0,0)
abline(v = 0)}
```

## Modeling
### Build Full Model:

```{r}
# TODO: Determine whether year should be included or not
full.model <- lm(pop ~., data = noout[-c(1,2,3,4)])
summary(full.model)
anova(full.model)
```

### Build Model based on high correlation (nrgy, live, dur, dnce, acous)

```{r}
model_high_corr <- lm(pop ~ nrgy + live + dur + dnce + acous, data = noout)
summary(model_high_corr)
anova(full.model,model_high_corr)
```

### Build Stepwise Model:

```{r}
library(MASS)
library(leaps)
step.model <- stepAIC(full.model, direction = "both",trace = FALSE)
summary(step.model)
anova(full.model,model_high_corr,step.model)
```

## Model Evaluation and Interpretation (TBD)
